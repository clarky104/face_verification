{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = glob.glob('train_data/*')\n",
    "train_imgs = np.array([img_to_array(load_img(img, target_size=(256,256,3))) for img in train_files])\n",
    "train_labels = to_categorical([int(float(filename.split('\\\\')[1].strip('.jpg'))) for filename in train_files])\n",
    "\n",
    "val_files = glob.glob('val_data/*')\n",
    "val_imgs = np.array([img_to_array(load_img(img, target_size=(256,256,3))) for img in val_files])\n",
    "val_labels = to_categorical([int(float(filename.split('\\\\')[1].strip('.jpg'))) for filename in val_files])\n",
    "\n",
    "test_files = glob.glob('test_data/*')\n",
    "test_imgs = np.array([img_to_array(load_img(img, target_size=(256,256,3))) for img in test_files])\n",
    "test_labels = to_categorical([int(float(filename.split('\\\\')[1].strip('.jpg'))) for filename in test_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n",
    "                              width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n",
    "                              horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "val_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_generator.flow(train_imgs, train_labels, batch_size=2)\n",
    "val_gen = val_generator.flow(val_imgs, val_labels, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('final_model.h5', save_best_only=True)\n",
    "earlystoppage = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "callbacks = [earlystoppage, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs\", \"fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Learning\n",
    "- Froze all layers in model to forego retraining everything\n",
    "- Added two layers onto it - first as another dense layer and the next as the image classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Xception(include_top = False, weights='imagenet', input_shape = (256, 256, 3))\n",
    "for layers in base.layers[:]:\n",
    "    layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_architecture = base.output\n",
    "pool = GlobalAveragePooling2D()(xception_architecture)\n",
    "dense = Dense(1024, activation='relu')(pool)\n",
    "predictions = Dense(114, activation='softmax')(dense) \n",
    "model = Model(inputs=base.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_gen, epochs = 5, verbose=1, validation_data = val_gen, shuffle = True, callbacks = [tensorboard_callback])\n",
    "\n",
    "train_loss, train_acc = model.evaluate(train_imgs, train_labels)\n",
    "test_loss, test_acc = model.evaluate(test_imgs, test_labels)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc * 100, test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions\n",
    "- Loaded in three pictures; the model only been trained on the first one\n",
    "- Predicted the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_ethan = 'preds/ethan.jpg'\n",
    "img_path_andrew = 'preds/andrew.jpg'\n",
    "img_path_nikki = 'preds/nikki.jpg'\n",
    "\n",
    "img1 = image.load_img(img_path_ethan, target_size = (256, 256))\n",
    "img2 = image.load_img(img_path_andrew, target_size = (256, 256))\n",
    "img3 = image.load_img(img_path_nikki, target_size = (256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_pred = image.img_to_array(img1)\n",
    "img1_pred = np.expand_dims(img1_pred, axis=0)\n",
    "img1_pred = preprocess_input(img1_pred)\n",
    "\n",
    "img2_pred = image.img_to_array(img2)\n",
    "img2_pred = np.expand_dims(img2_pred, axis=0)\n",
    "img2_pred = preprocess_input(img2_pred)\n",
    "\n",
    "img3_pred = image.img_to_array(img3)\n",
    "img3_pred = np.expand_dims(img3_pred, axis=0)\n",
    "img3_pred = preprocess_input(img3_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = model.predict(img1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.where(arr == np.amin(arr))\n",
    "print('List of Indices of maximum element :', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
